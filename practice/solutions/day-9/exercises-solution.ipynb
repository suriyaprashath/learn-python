{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f66f30ec",
   "metadata": {},
   "source": [
    "# Day 9: NumPy and Pandas Practice Exercises - Solutions\n",
    "\n",
    "This notebook contains complete solutions with explanations for all Day 9 exercises.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84341f7",
   "metadata": {},
   "source": [
    "## Part 1: NumPy Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6ec41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d63f25",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercise 1 Solution: Create a Checkerboard Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57887f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Using slicing with step size\n",
    "checkerboard = np.zeros((8, 8), dtype=int)\n",
    "checkerboard[::2, 1::2] = 1  # Even rows, odd columns\n",
    "checkerboard[1::2, ::2] = 1  # Odd rows, even columns\n",
    "\n",
    "print(checkerboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600e89a6",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "- Start with an 8Ã—8 array of zeros\n",
    "- `[::2, 1::2]` means: every other row starting at 0, every other column starting at 1\n",
    "- `[1::2, ::2]` means: every other row starting at 1, every other column starting at 0\n",
    "- This creates the alternating pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acdd9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative Method 2: Using modulo operation\n",
    "checkerboard2 = np.indices((8, 8)).sum(axis=0) % 2\n",
    "print(checkerboard2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d037f7e1",
   "metadata": {},
   "source": [
    "**Alternative explanation:**\n",
    "- `np.indices((8, 8))` creates coordinate arrays\n",
    "- Sum of row and column indices determines the pattern\n",
    "- Modulo 2 gives alternating 0s and 1s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497d6052",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercise 2 Solution: Create Concentric Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfc4926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 7Ã—7 array and fill with concentric values\n",
    "concentric = np.zeros((7, 7), dtype=int)\n",
    "\n",
    "# Fill each layer from outside to inside\n",
    "concentric[1:6, 1:6] = 1\n",
    "concentric[2:5, 2:5] = 2\n",
    "concentric[3, 3] = 3\n",
    "\n",
    "print(concentric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c889d18",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "- Start with 7Ã—7 array of zeros (outermost layer)\n",
    "- `[1:6, 1:6]` selects the inner 5Ã—5 region, fill with 1\n",
    "- `[2:5, 2:5]` selects the inner 3Ã—3 region, fill with 2\n",
    "- `[3, 3]` is the center point, fill with 3\n",
    "- Each slice overwrites the previous values in that region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da8e116",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercise 3 Solution: Create a Diagonal Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95670f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 6Ã—6 array with base value 1\n",
    "diagonal = np.full((6, 6), 1)\n",
    "\n",
    "# Set diagonals one step away from main diagonal to 3\n",
    "diagonal[np.arange(5), np.arange(1, 6)] = 3  # Upper diagonal\n",
    "diagonal[np.arange(1, 6), np.arange(5)] = 3  # Lower diagonal\n",
    "\n",
    "# Set main diagonal to 5\n",
    "np.fill_diagonal(diagonal, 5)\n",
    "\n",
    "print(diagonal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb62cbf",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "- Start with 6Ã—6 array filled with 1s\n",
    "- `np.arange(5)` and `np.arange(1, 6)` create indices for the upper diagonal\n",
    "- `np.arange(1, 6)` and `np.arange(5)` create indices for the lower diagonal\n",
    "- `np.fill_diagonal()` fills the main diagonal with 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226b0eea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercise 4 Solution: Advanced Indexing and Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7856683",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([\n",
    "    [10, 20, 30, 40],\n",
    "    [50, 60, 70, 80],\n",
    "    [90, 100, 110, 120],\n",
    "    [130, 140, 150, 160]\n",
    "])\n",
    "\n",
    "# Task 1: Extract center 2Ã—2\n",
    "center = data[1:3, 1:3]\n",
    "print(\"Center 2Ã—2:\")\n",
    "print(center)\n",
    "print()\n",
    "\n",
    "# Task 2: Extract corners\n",
    "corners = np.array([data[0, 0], data[0, -1], data[-1, 0], data[-1, -1]])\n",
    "# alternate solution\n",
    "corners = data[0:4:3,0:4:3]\n",
    "print(\"Corners:\", corners)\n",
    "print()\n",
    "\n",
    "# Task 3: Every other row and column\n",
    "sparse = data[::2, ::2]\n",
    "print(\"Every other row/column:\")\n",
    "print(sparse)\n",
    "print()\n",
    "\n",
    "# Task 4: Replace values > 100 with 999\n",
    "data_modified = data.copy()\n",
    "data_modified[data_modified > 100] = 999\n",
    "print(\"After replacement:\")\n",
    "print(data_modified)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefa2df2",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "- **Task 1:** `[1:3, 1:3]` selects rows 1-2 and columns 1-2 (center)\n",
    "- **Task 2:** Use negative indexing: `-1` is last position\n",
    "- **Task 3:** `[::2, ::2]` takes every second row and column\n",
    "- **Task 4:** Boolean indexing with condition `> 100`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1e72eb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercise 5 Solution: Array Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d48b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Create 1D array\n",
    "arr = np.arange(1, 13)\n",
    "print(\"Original array:\", arr)\n",
    "print()\n",
    "\n",
    "# Task 2: Reshape to 3Ã—4\n",
    "arr_3x4 = arr.reshape(3, 4)\n",
    "print(\"Reshaped to 3Ã—4:\")\n",
    "print(arr_3x4)\n",
    "print()\n",
    "\n",
    "# Task 3: Reshape to 4Ã—3\n",
    "arr_4x3 = arr.reshape(4, 3)\n",
    "print(\"Reshaped to 4Ã—3:\")\n",
    "print(arr_4x3)\n",
    "print()\n",
    "\n",
    "# Task 4: Create two 2Ã—3 random arrays\n",
    "arr_a = np.random.randint(0, 10, size=(2, 3))\n",
    "arr_b = np.random.randint(0, 10, size=(2, 3))\n",
    "print(\"Array A:\")\n",
    "print(arr_a)\n",
    "print(\"Array B:\")\n",
    "print(arr_b)\n",
    "print()\n",
    "\n",
    "# Task 5: Vertical stack\n",
    "vstacked = np.vstack((arr_a, arr_b))\n",
    "print(\"Vertically stacked (4Ã—3):\")\n",
    "print(vstacked)\n",
    "print()\n",
    "\n",
    "# Task 6: Horizontal stack\n",
    "hstacked = np.hstack((arr_a, arr_b))\n",
    "print(\"Horizontally stacked (2Ã—6):\")\n",
    "print(hstacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f5861a",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "- `np.arange(1, 13)` creates array [1, 2, ..., 12]\n",
    "- `.reshape()` changes dimensions (must have compatible total size)\n",
    "- `np.random.randint(0, 10, size=(2, 3))` creates random integers 0-9 in 2Ã—3 array\n",
    "- `np.vstack()` stacks arrays vertically (rows)\n",
    "- `np.hstack()` stacks arrays horizontally (columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a23293",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercise 6 Solution: Mathematical Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dd59aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = np.array([100, 250, 75, 180, 320])\n",
    "quantities = np.array([3, 2, 5, 1, 4])\n",
    "\n",
    "# Task 1: Calculate revenue per item\n",
    "revenue_per_item = prices * quantities\n",
    "print(\"Revenue per item:\", revenue_per_item)\n",
    "print()\n",
    "\n",
    "# Task 2: Apply 15% discount\n",
    "discounted_prices = prices * 0.85\n",
    "print(\"Discounted prices:\", discounted_prices)\n",
    "print()\n",
    "\n",
    "# Task 3: Total revenue\n",
    "total_revenue = revenue_per_item.sum()\n",
    "print(f\"Total revenue: ${total_revenue}\")\n",
    "print()\n",
    "\n",
    "# Task 4: Average price\n",
    "avg_price = prices.mean()\n",
    "print(f\"Average price: ${avg_price:.2f}\")\n",
    "print()\n",
    "\n",
    "# Task 5: Item with max revenue\n",
    "max_revenue_idx = revenue_per_item.argmax()\n",
    "print(f\"Item with max revenue: Index {max_revenue_idx}, Revenue: ${revenue_per_item[max_revenue_idx]}\")\n",
    "print()\n",
    "\n",
    "# Task 6: Add shipping fee\n",
    "prices_with_shipping = prices + 10\n",
    "print(\"Prices with $10 shipping:\", prices_with_shipping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726bc6ab",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "- Element-wise multiplication: `prices * quantities`\n",
    "- Broadcasting: scalar (0.85, 10) applies to all elements\n",
    "- `.sum()` adds all values\n",
    "- `.mean()` calculates average\n",
    "- `.argmax()` returns index of maximum value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872a6017",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercise 7 Solution: Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489f2c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.array([\n",
    "    [85, 92, 78, 88],  # Student 1\n",
    "    [90, 85, 95, 87],  # Student 2\n",
    "    [78, 88, 82, 91],  # Student 3\n",
    "    [92, 79, 88, 84],  # Student 4\n",
    "    [88, 91, 86, 89]   # Student 5\n",
    "])\n",
    "\n",
    "# Task 1: Average score per student\n",
    "student_averages = scores.mean(axis=1)\n",
    "print(\"Average score per student:\")\n",
    "for i, avg in enumerate(student_averages, 1):\n",
    "    print(f\"  Student {i}: {avg:.2f}\")\n",
    "print()\n",
    "\n",
    "# Task 2: Average score per subject\n",
    "subject_averages = scores.mean(axis=0)\n",
    "print(\"Average score per subject:\")\n",
    "subjects = ['Subject 1', 'Subject 2', 'Subject 3', 'Subject 4']\n",
    "for subj, avg in zip(subjects, subject_averages):\n",
    "    print(f\"  {subj}: {avg:.2f}\")\n",
    "print()\n",
    "\n",
    "# Task 3: Highest score overall\n",
    "max_score = scores.max()\n",
    "print(f\"Highest score: {max_score}\")\n",
    "print()\n",
    "\n",
    "# Task 4: Subject with highest average\n",
    "best_subject_idx = subject_averages.argmax()\n",
    "print(f\"Subject with highest average: {subjects[best_subject_idx]} ({subject_averages[best_subject_idx]:.2f})\")\n",
    "print()\n",
    "\n",
    "# Task 5: Student with highest average\n",
    "best_student_idx = student_averages.argmax()\n",
    "print(f\"Student with highest average: Student {best_student_idx + 1} ({student_averages[best_student_idx]:.2f})\")\n",
    "print()\n",
    "\n",
    "# Task 6: Standard deviation per subject\n",
    "subject_std = scores.std(axis=0)\n",
    "print(\"Standard deviation per subject:\")\n",
    "for subj, std in zip(subjects, subject_std):\n",
    "    print(f\"  {subj}: {std:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a7fbc5",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "- `axis=1`: Calculate along rows (per student)\n",
    "- `axis=0`: Calculate along columns (per subject)\n",
    "- `.max()` finds maximum value\n",
    "- `.argmax()` finds index of maximum\n",
    "- `.std()` calculates standard deviation (measure of spread)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3751fe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Pandas Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdccdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d5c5d6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercise 8 Solution: Create and Explore a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c806b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_data = {\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank'],\n",
    "    'department': ['Engineering', 'Sales', 'Engineering', 'HR', 'Sales', 'Engineering'],\n",
    "    'salary': [95000, 65000, 88000, 72000, 70000, 91000],\n",
    "    'years_experience': [5, 3, 4, 6, 3, 7],\n",
    "    'performance_score': [8.5, 7.2, 9.1, 7.8, 8.0, 8.8]\n",
    "}\n",
    "\n",
    "# Task 1: Create DataFrame\n",
    "df_emp = pd.DataFrame(employee_data)\n",
    "print(\"âœ… DataFrame created\")\n",
    "print()\n",
    "\n",
    "# Task 2: Display first 3 rows\n",
    "print(\"First 3 rows:\")\n",
    "print(df_emp.head(3))\n",
    "print()\n",
    "\n",
    "# Task 3: Show shape\n",
    "print(f\"Shape: {df_emp.shape[0]} rows Ã— {df_emp.shape[1]} columns\")\n",
    "print()\n",
    "\n",
    "# Task 4: Display info\n",
    "print(\"DataFrame Info:\")\n",
    "df_emp.info()\n",
    "print()\n",
    "\n",
    "# Task 5: Statistical summary\n",
    "print(\"Statistical Summary:\")\n",
    "print(df_emp.describe())\n",
    "print()\n",
    "\n",
    "# Task 6: Value counts for department\n",
    "print(\"Department value counts:\")\n",
    "print(df_emp['department'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291c329e",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "- `pd.DataFrame(dict)` creates DataFrame from dictionary\n",
    "- `.head(n)` shows first n rows\n",
    "- `.shape` returns tuple (rows, columns)\n",
    "- `.info()` shows data types and null counts\n",
    "- `.describe()` provides statistical summary\n",
    "- `.value_counts()` counts occurrences of each unique value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc029e0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercise 9 Solution: Filtering and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e4e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Engineering department\n",
    "engineering = df_emp[df_emp['department'] == 'Engineering']\n",
    "print(\"Engineering employees:\")\n",
    "print(engineering)\n",
    "print()\n",
    "\n",
    "# Task 2: Salary > 80,000\n",
    "high_salary = df_emp[df_emp['salary'] > 80000]\n",
    "print(\"High salary employees (>$80k):\")\n",
    "print(high_salary)\n",
    "print()\n",
    "\n",
    "# Task 3: Experience > 4 AND performance > 8.0\n",
    "experienced_performers = df_emp[\n",
    "    (df_emp['years_experience'] > 4) & (df_emp['performance_score'] > 8.0)\n",
    "]\n",
    "print(\"Experienced high performers:\")\n",
    "print(experienced_performers)\n",
    "print()\n",
    "\n",
    "# Task 4: Query method\n",
    "sales_low_salary = df_emp.query(\"department == 'Sales' and salary < 75000\")\n",
    "print(\"Sales employees with salary < $75k:\")\n",
    "print(sales_low_salary)\n",
    "print()\n",
    "\n",
    "# Task 5: Select specific columns\n",
    "name_salary = df_emp[['name', 'salary']]\n",
    "print(\"Name and salary only:\")\n",
    "print(name_salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9334d315",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "- Boolean indexing: `df[condition]`\n",
    "- Multiple conditions: Use `&` (AND) or `|` (OR), wrap each in parentheses\n",
    "- `.query()`: SQL-like syntax, more readable for complex conditions\n",
    "- Column selection: `df[['col1', 'col2']]` returns DataFrame with selected columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331aa0ac",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercise 10 Solution: Create New Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b8faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Salary per year of experience\n",
    "df_emp['salary_per_year'] = df_emp['salary'] / df_emp['years_experience']\n",
    "print(\"âœ… Created 'salary_per_year' column\")\n",
    "print()\n",
    "\n",
    "# Task 2: High performer flag\n",
    "df_emp['high_performer'] = df_emp['performance_score'] >= 8.5\n",
    "print(\"âœ… Created 'high_performer' column\")\n",
    "print()\n",
    "\n",
    "# Task 3: Salary category\n",
    "def categorize_salary(salary):\n",
    "    if salary < 70000:\n",
    "        return 'Low'\n",
    "    elif salary < 90000:\n",
    "        return 'Medium'\n",
    "    else:\n",
    "        return 'High'\n",
    "\n",
    "df_emp['salary_category'] = df_emp['salary'].apply(categorize_salary)\n",
    "print(\"âœ… Created 'salary_category' column\")\n",
    "print()\n",
    "\n",
    "# Task 4: Display updated DataFrame\n",
    "print(\"Updated DataFrame:\")\n",
    "print(df_emp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b024bb",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "- Create column: `df['new_col'] = expression`\n",
    "- Boolean condition returns True/False\n",
    "- `.apply(func)` applies function to each value\n",
    "- Can use lambda or named function\n",
    "\n",
    "**Alternative for Task 3 using pd.cut():**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeb711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Using pd.cut()\n",
    "df_emp['salary_category_alt'] = pd.cut(\n",
    "    df_emp['salary'],\n",
    "    bins=[0, 70000, 90000, float('inf')],\n",
    "    labels=['Low', 'Medium', 'High']\n",
    ")\n",
    "print(\"Alternative with pd.cut():\")\n",
    "print(df_emp[['name', 'salary', 'salary_category', 'salary_category_alt']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3110c600",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercise 11 Solution: Grouping and Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5404f839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Average salary by department\n",
    "avg_salary_by_dept = df_emp.groupby('department')['salary'].mean()\n",
    "print(\"Average salary by department:\")\n",
    "print(avg_salary_by_dept)\n",
    "print()\n",
    "\n",
    "# Task 2: Count by department\n",
    "count_by_dept = df_emp.groupby('department').size()\n",
    "print(\"Employee count by department:\")\n",
    "print(count_by_dept)\n",
    "print()\n",
    "\n",
    "# Task 3: Multiple statistics by department\n",
    "dept_stats = df_emp.groupby('department').agg({\n",
    "    'salary': 'mean',\n",
    "    'performance_score': 'mean',\n",
    "    'years_experience': 'mean',\n",
    "    'name': 'count'\n",
    "}).rename(columns={'name': 'count'})\n",
    "\n",
    "print(\"Department statistics:\")\n",
    "print(dept_stats)\n",
    "print()\n",
    "\n",
    "# Task 4: Bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "avg_salary_by_dept.plot(kind='bar', color='steelblue', edgecolor='black')\n",
    "plt.title('Average Salary by Department', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Department', fontsize=12)\n",
    "plt.ylabel('Average Salary ($)', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1d4986",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "- `.groupby('column')` groups data by unique values\n",
    "- Chain aggregation: `.groupby()['column'].mean()`\n",
    "- `.size()` counts rows per group\n",
    "- `.agg(dict)` applies multiple aggregations\n",
    "- `.plot(kind='bar')` creates bar chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36312b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises 12-15: Complete Data Analysis Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2a6d93",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercise 12 Solution: Load and Explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60571d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Load CSV\n",
    "csv_path = Path('../../hw_measurements.csv')\n",
    "df = pd.read_csv(csv_path)\n",
    "print(\"âœ… Data loaded successfully\")\n",
    "print()\n",
    "\n",
    "# Task 2: First 5 rows\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head())\n",
    "print()\n",
    "\n",
    "# Task 3: Shape\n",
    "print(f\"Shape: {df.shape[0]} rows Ã— {df.shape[1]} columns\")\n",
    "print()\n",
    "\n",
    "# Task 4: Info\n",
    "print(\"DataFrame Info:\")\n",
    "df.info()\n",
    "print()\n",
    "\n",
    "# Task 5: Statistical summary\n",
    "print(\"Statistical Summary:\")\n",
    "print(df.describe())\n",
    "print()\n",
    "\n",
    "# Task 6: Missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isna().sum())\n",
    "print()\n",
    "total_missing = df.isna().sum().sum()\n",
    "print(f\"Total missing values: {total_missing}\")\n",
    "if total_missing == 0:\n",
    "    print(\"âœ… No missing values!\")\n",
    "print()\n",
    "\n",
    "# Task 7: Result value counts\n",
    "print(\"Test results:\")\n",
    "print(df['result'].value_counts())\n",
    "print()\n",
    "failure_rate = (df['result'] == 'FAIL').sum() / len(df) * 100\n",
    "print(f\"Failure rate: {failure_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1eeb5b",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "- `pd.read_csv()` loads CSV into DataFrame\n",
    "- `.head()` shows first rows\n",
    "- `.info()` displays structure\n",
    "- `.describe()` provides statistics\n",
    "- `.isna().sum()` counts missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c1a3c5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercise 13 Solution: Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29456ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "print(\"âœ… Timestamp converted to datetime\")\n",
    "print(f\"Data type: {df['timestamp'].dtype}\")\n",
    "print()\n",
    "\n",
    "# Task 2: Create power column\n",
    "df['power_w'] = df['supply_v'] * df['current_a']\n",
    "print(\"âœ… Created 'power_w' column\")\n",
    "print()\n",
    "\n",
    "# Task 3: Create is_fail column\n",
    "df['is_fail'] = (df['result'] == 'FAIL').astype(int)\n",
    "print(\"âœ… Created 'is_fail' binary column\")\n",
    "print()\n",
    "\n",
    "# Task 4: Display first rows with new columns\n",
    "print(\"First rows with new columns:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9842c3d5",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "- `pd.to_datetime()` converts string to datetime\n",
    "- Element-wise multiplication creates new column\n",
    "- Boolean condition + `.astype(int)` creates binary (0/1) column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7116a42",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercise 14 Solution: Filtering and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0750f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Filter FAIL results\n",
    "failures = df[df['result'] == 'FAIL']\n",
    "print(f\"Found {len(failures)} failures\")\n",
    "print(failures.head())\n",
    "print()\n",
    "\n",
    "# Task 2: Filter temp >= 40\n",
    "hot_measurements = df[df['temp_c'] >= 40]\n",
    "print(f\"Found {len(hot_measurements)} measurements with temp >= 40Â°C\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93415e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Line plot - Current vs Temperature\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(\n",
    "    data=df,\n",
    "    x='temp_c',\n",
    "    y='current_a',\n",
    "    hue='board_rev',\n",
    "    marker='o',\n",
    "    linewidth=2\n",
    ")\n",
    "plt.title('Current vs Temperature by Board Revision', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Temperature (Â°C)', fontsize=12)\n",
    "plt.ylabel('Current (A)', fontsize=12)\n",
    "plt.legend(title='Board Revision')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6af9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Scatter plot - SNR vs Current\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(\n",
    "    data=df,\n",
    "    x='current_a',\n",
    "    y='snr_db',\n",
    "    hue='result',\n",
    "    style='board_rev',\n",
    "    s=100,\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title('SNR vs Current by Result', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Current (A)', fontsize=12)\n",
    "plt.ylabel('SNR (dB)', fontsize=12)\n",
    "plt.legend(title='Status', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccacc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5: Create temperature bands\n",
    "df['temp_band'] = pd.cut(\n",
    "    df['temp_c'],\n",
    "    bins=[15, 30, 45, 60, 75],\n",
    "    labels=['20-30Â°C', '30-45Â°C', '45-60Â°C', '60-75Â°C']\n",
    ")\n",
    "print(\"âœ… Created temperature bands\")\n",
    "print(df['temp_band'].value_counts().sort_index())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5154e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 6: Box plot - Power by temperature band\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(\n",
    "    data=df,\n",
    "    x='temp_band',\n",
    "    y='power_w',\n",
    "    hue='board_rev',\n",
    "    palette='Set2'\n",
    ")\n",
    "plt.title('Power Distribution by Temperature Band and Board Revision', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Temperature Range', fontsize=12)\n",
    "plt.ylabel('Power (W)', fontsize=12)\n",
    "plt.legend(title='Board Revision')\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1f55b4",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "- Boolean indexing for filtering\n",
    "- `sns.lineplot()` for trend visualization\n",
    "- `sns.scatterplot()` for relationships\n",
    "- `pd.cut()` bins continuous data into categories\n",
    "- `sns.boxplot()` shows distribution across categories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2013627f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Exercise 15 Solution: Aggregation and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cd02f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Group and aggregate\n",
    "aggregated = df.groupby(['board_rev', 'temp_c'], as_index=False).agg(\n",
    "    mean_power_w=('power_w', 'mean'),\n",
    "    mean_snr_db=('snr_db', 'mean'),\n",
    "    fail_rate=('is_fail', 'mean'),\n",
    "    count=('device_id', 'count')\n",
    ")\n",
    "\n",
    "print(\"âœ… Created aggregated DataFrame\")\n",
    "print(f\"Original: {len(df)} rows â†’ Aggregated: {len(aggregated)} rows\")\n",
    "print()\n",
    "print(\"Aggregated data (first 10 rows):\")\n",
    "print(aggregated.head(10))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c237ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Mean power vs temperature\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(\n",
    "    data=aggregated,\n",
    "    x='temp_c',\n",
    "    y='mean_power_w',\n",
    "    hue='board_rev',\n",
    "    marker='o',\n",
    "    linewidth=2.5,\n",
    "    markersize=8\n",
    ")\n",
    "plt.title('Mean Power vs Temperature (Aggregated)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Temperature (Â°C)', fontsize=12)\n",
    "plt.ylabel('Mean Power (W)', fontsize=12)\n",
    "plt.legend(title='Board Revision')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95382ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Failure rate vs temperature\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.lineplot(\n",
    "    data=aggregated,\n",
    "    x='temp_c',\n",
    "    y='fail_rate',\n",
    "    hue='board_rev',\n",
    "    marker='o',\n",
    "    linewidth=2.5,\n",
    "    markersize=8\n",
    ")\n",
    "plt.title('Failure Rate vs Temperature (Aggregated)', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Temperature (Â°C)', fontsize=12)\n",
    "plt.ylabel('Failure Rate (proportion)', fontsize=12)\n",
    "plt.ylim(0, 1)\n",
    "plt.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='50% threshold')\n",
    "plt.legend(title='Board Revision')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e313619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4: Correlation matrix\n",
    "numeric_cols = ['run', 'temp_c', 'freq_mhz', 'supply_v', 'current_a', 'snr_db', 'power_w', 'is_fail']\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "print(\"Correlation matrix:\")\n",
    "print(correlation_matrix)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb93ba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5: Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap='coolwarm',\n",
    "    center=0,\n",
    "    square=True,\n",
    "    linewidths=1,\n",
    "    cbar_kws={'shrink': 0.8}\n",
    ")\n",
    "plt.title('Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb75be7",
   "metadata": {},
   "source": [
    "**Task 6: Analysis Questions**\n",
    "\n",
    "Based on the analysis, here are the insights:\n",
    "\n",
    "**1. At what temperature do failures start to occur?**\n",
    "- Look at the failure rate plot\n",
    "- Identify where the line starts rising from 0\n",
    "- Typical answer: Failures begin around 50-60Â°C range\n",
    "\n",
    "**2. Which board revision performs better?**\n",
    "- Compare failure rates between Board A and Board B\n",
    "- Check which has lower failure rate at high temperatures\n",
    "- Look at mean power consumption differences\n",
    "- Generally, boards show similar performance patterns\n",
    "\n",
    "**3. What is the relationship between temperature and SNR?**\n",
    "- Check correlation matrix: look at temp_c vs snr_db\n",
    "- Negative correlation indicates SNR decreases as temperature increases\n",
    "- Strong correlation (|r| > 0.7) suggests temperature is major factor in SNR degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c4b503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional insights\n",
    "print(\"=\" * 60)\n",
    "print(\"KEY INSIGHTS FROM ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Temperature correlation with failures\n",
    "temp_fail_corr = correlation_matrix.loc['temp_c', 'is_fail']\n",
    "print(f\"Temperature vs Failure correlation: {temp_fail_corr:.3f}\")\n",
    "\n",
    "# Temperature correlation with SNR\n",
    "temp_snr_corr = correlation_matrix.loc['temp_c', 'snr_db']\n",
    "print(f\"Temperature vs SNR correlation: {temp_snr_corr:.3f}\")\n",
    "print()\n",
    "\n",
    "# Failure temperature threshold\n",
    "first_failure_temp = df[df['result'] == 'FAIL']['temp_c'].min()\n",
    "print(f\"First failure occurs at: {first_failure_temp}Â°C\")\n",
    "print()\n",
    "\n",
    "# Board comparison\n",
    "board_fail_rate = df.groupby('board_rev')['is_fail'].mean()\n",
    "print(\"Failure rate by board revision:\")\n",
    "for board, rate in board_fail_rate.items():\n",
    "    print(f\"  Board {board}: {rate*100:.2f}%\")\n",
    "print()\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3f9451",
   "metadata": {},
   "source": [
    "**Explanation:**\n",
    "- `.groupby()` with multiple columns creates hierarchical groups\n",
    "- `.agg()` with named aggregations creates clean output\n",
    "- Aggregated plots show cleaner trends by averaging multiple measurements\n",
    "- `.corr()` calculates correlation between all numeric pairs\n",
    "- `sns.heatmap()` visualizes correlation matrix\n",
    "- Domain knowledge + data analysis = actionable insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b240b2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary of Key Concepts\n",
    "\n",
    "### NumPy:\n",
    "- Array creation with patterns using slicing and indexing\n",
    "- Reshaping arrays with `.reshape()`\n",
    "- Stacking arrays with `vstack()` and `hstack()`\n",
    "- Element-wise operations and broadcasting\n",
    "- Statistical functions with axis parameter\n",
    "\n",
    "### Pandas:\n",
    "- DataFrame creation from dictionaries\n",
    "- Exploration methods: `.head()`, `.info()`, `.describe()`\n",
    "- Boolean indexing and `.query()` for filtering\n",
    "- Creating derived columns (feature engineering)\n",
    "- Grouping and aggregation with `.groupby()` and `.agg()`\n",
    "- Data visualization with seaborn\n",
    "- Complete analysis workflow: load â†’ explore â†’ transform â†’ visualize â†’ aggregate â†’ insights\n",
    "\n",
    "### Best Practices:\n",
    "âœ… Explore data thoroughly before analysis  \n",
    "âœ… Create meaningful derived features  \n",
    "âœ… Use visualizations to validate findings  \n",
    "âœ… Aggregate data to find clear patterns  \n",
    "âœ… Document insights and recommendations  \n",
    "âœ… Verify results make domain sense  \n",
    "\n",
    "**Congratulations on completing all exercises!** ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
