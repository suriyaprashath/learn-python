{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4605ee4d",
   "metadata": {},
   "source": [
    "# Pytest Parametrization\n",
    "\n",
    "## What You'll Learn\n",
    "- What is parametrization and why use it?\n",
    "- The `@pytest.mark.parametrize` decorator\n",
    "- Testing multiple inputs with one test\n",
    "- Parametrizing with multiple arguments\n",
    "- Using IDs for readable test names\n",
    "- Combining parametrization with fixtures\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c01d39f",
   "metadata": {},
   "source": [
    "## The Problem: Repetitive Tests\n",
    "\n",
    "Imagine you want to test a function with different inputs.\n",
    "\n",
    "### Example: Testing a Math Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9603cb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# math_utils.py\n",
    "def is_even(number):\n",
    "    \"\"\"Check if a number is even.\"\"\"\n",
    "    return number % 2 == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd52286e",
   "metadata": {},
   "source": [
    "### Without Parametrization (Repetitive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccabc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_is_even_with_2():\n",
    "    assert is_even(2) is True\n",
    "\n",
    "def test_is_even_with_4():\n",
    "    assert is_even(4) is True\n",
    "\n",
    "def test_is_even_with_6():\n",
    "    assert is_even(6) is True\n",
    "\n",
    "def test_is_even_with_1():\n",
    "    assert is_even(1) is False\n",
    "\n",
    "def test_is_even_with_3():\n",
    "    assert is_even(3) is False\n",
    "\n",
    "def test_is_even_with_5():\n",
    "    assert is_even(5) is False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50cd74d",
   "metadata": {},
   "source": [
    "**Problems:**\n",
    "- ‚ùå Lots of repetition\n",
    "- ‚ùå Need to write a new function for each test case\n",
    "- ‚ùå Hard to add more test cases\n",
    "- ‚ùå Testing 100 values? Write 100 functions?\n",
    "\n",
    "**Solution:** Parametrization! üéâ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2c72f2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## What is Parametrization?\n",
    "\n",
    "**Parametrization** lets you run the same test with different inputs automatically.\n",
    "\n",
    "**Think of it like a loop for tests:**\n",
    "- You provide a list of test inputs\n",
    "- Pytest runs your test once for each input\n",
    "- Each run is a separate test\n",
    "\n",
    "**Benefits:**\n",
    "- ‚úÖ Write test logic once, test many inputs\n",
    "- ‚úÖ Easy to add more test cases\n",
    "- ‚úÖ Cleaner, more maintainable code\n",
    "- ‚úÖ Clear test output showing which inputs passed/failed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd41d8f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Basic Parametrization\n",
    "\n",
    "### Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defe0395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "@pytest.mark.parametrize(\"parameter_name\", [value1, value2, value3])\n",
    "def test_function(parameter_name):\n",
    "    # Test code using parameter_name\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c96a04c",
   "metadata": {},
   "source": [
    "### Example 1: Simple Parametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98b7895",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\"number\", [2, 4, 6, 8, 10])\n",
    "def test_is_even_true(number):\n",
    "    \"\"\"Test that even numbers return True.\"\"\"\n",
    "    assert is_even(number) is True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2679873",
   "metadata": {},
   "source": [
    "**What happens:**\n",
    "1. Pytest runs this test 5 times\n",
    "2. Each time with a different value for `number`\n",
    "3. Test 1: `number = 2`\n",
    "4. Test 2: `number = 4`\n",
    "5. Test 3: `number = 6`\n",
    "6. And so on...\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "test_example.py::test_is_even_true[2] PASSED    [ 20%]\n",
    "test_example.py::test_is_even_true[4] PASSED    [ 40%]\n",
    "test_example.py::test_is_even_true[6] PASSED    [ 60%]\n",
    "test_example.py::test_is_even_true[8] PASSED    [ 80%]\n",
    "test_example.py::test_is_even_true[10] PASSED   [100%]\n",
    "```\n",
    "\n",
    "Notice the `[2]`, `[4]` etc. - showing which input was tested!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f7bac2",
   "metadata": {},
   "source": [
    "### Example 2: Testing Both True and False Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d146a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\"number\", [1, 3, 5, 7, 9])\n",
    "def test_is_even_false(number):\n",
    "    \"\"\"Test that odd numbers return False.\"\"\"\n",
    "    assert is_even(number) is False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa03054",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Parametrizing with Multiple Arguments\n",
    "\n",
    "You can test with multiple inputs at once using tuples.\n",
    "\n",
    "### Syntax for Multiple Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb00412",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\"input1, input2, expected\", [\n",
    "    (value1a, value1b, expected1),\n",
    "    (value2a, value2b, expected2),\n",
    "    (value3a, value3b, expected3),\n",
    "])\n",
    "def test_function(input1, input2, expected):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6573abe",
   "metadata": {},
   "source": [
    "### Example 3: Testing Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36a1832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a, b):\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@pytest.mark.parametrize(\"a, b, expected\", [\n",
    "    (2, 3, 5),\n",
    "    (0, 0, 0),\n",
    "    (-1, 1, 0),\n",
    "    (10, 5, 15),\n",
    "    (100, 200, 300),\n",
    "])\n",
    "def test_add(a, b, expected):\n",
    "    \"\"\"Test addition with multiple inputs.\"\"\"\n",
    "    result = add(a, b)\n",
    "    assert result == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc4231f",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "```\n",
    "test_example.py::test_add[2-3-5] PASSED       [ 20%]\n",
    "test_example.py::test_add[0-0-0] PASSED       [ 40%]\n",
    "test_example.py::test_add[-1-1-0] PASSED      [ 60%]\n",
    "test_example.py::test_add[10-5-15] PASSED     [ 80%]\n",
    "test_example.py::test_add[100-200-300] PASSED [100%]\n",
    "```\n",
    "\n",
    "Each test shows the input values: `[a-b-expected]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b3d50e",
   "metadata": {},
   "source": [
    "### Example 4: String Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf277e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capitalize_name(name):\n",
    "    \"\"\"Capitalize first letter of each word.\"\"\"\n",
    "    return name.title()\n",
    "\n",
    "@pytest.mark.parametrize(\"input_name, expected\", [\n",
    "    (\"alice\", \"Alice\"),\n",
    "    (\"bob smith\", \"Bob Smith\"),\n",
    "    (\"CHARLIE\", \"Charlie\"),\n",
    "    (\"mary jane watson\", \"Mary Jane Watson\"),\n",
    "    (\"\", \"\"),\n",
    "])\n",
    "def test_capitalize_name(input_name, expected):\n",
    "    \"\"\"Test name capitalization.\"\"\"\n",
    "    result = capitalize_name(input_name)\n",
    "    assert result == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aecb00",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Using IDs for Readable Test Names\n",
    "\n",
    "By default, pytest shows parameter values in test names. But sometimes you want more descriptive names.\n",
    "\n",
    "### Example Without IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfceb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\"age, expected\", [\n",
    "    (15, False),\n",
    "    (17, False),\n",
    "    (18, True),\n",
    "    (21, True),\n",
    "])\n",
    "def test_is_adult(age, expected):\n",
    "    \"\"\"Test age verification.\"\"\"\n",
    "    assert (age >= 18) == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772e5595",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "```\n",
    "test_example.py::test_is_adult[15-False] PASSED\n",
    "test_example.py::test_is_adult[17-False] PASSED\n",
    "test_example.py::test_is_adult[18-True] PASSED\n",
    "test_example.py::test_is_adult[21-True] PASSED\n",
    "```\n",
    "\n",
    "### Example With IDs (More Readable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fa7f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\"age, expected\", [\n",
    "    (15, False),\n",
    "    (17, False),\n",
    "    (18, True),\n",
    "    (21, True),\n",
    "], ids=[\"minor-15\", \"minor-17\", \"adult-18\", \"adult-21\"])\n",
    "def test_is_adult_with_ids(age, expected):\n",
    "    \"\"\"Test age verification with readable IDs.\"\"\"\n",
    "    assert (age >= 18) == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da01689",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "```\n",
    "test_example.py::test_is_adult_with_ids[minor-15] PASSED\n",
    "test_example.py::test_is_adult_with_ids[minor-17] PASSED\n",
    "test_example.py::test_is_adult_with_ids[adult-18] PASSED\n",
    "test_example.py::test_is_adult_with_ids[adult-21] PASSED\n",
    "```\n",
    "\n",
    "Much clearer! üéâ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a651f48",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Practical Examples\n",
    "\n",
    "### Example 5: Password Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1494e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_password(password):\n",
    "    \"\"\"\n",
    "    Validate password:\n",
    "    - At least 8 characters\n",
    "    - Contains at least one number\n",
    "    - Contains at least one uppercase letter\n",
    "    \"\"\"\n",
    "    if len(password) < 8:\n",
    "        return False\n",
    "    if not any(char.isdigit() for char in password):\n",
    "        return False\n",
    "    if not any(char.isupper() for char in password):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "@pytest.mark.parametrize(\"password, expected\", [\n",
    "    (\"Pass1234\", True),         # Valid\n",
    "    (\"PASSWORD1\", True),         # Valid\n",
    "    (\"MyP@ssw0rd\", True),       # Valid\n",
    "    (\"short1\", False),           # Too short\n",
    "    (\"nouppercase1\", False),     # No uppercase\n",
    "    (\"NONUMBER\", False),         # No number\n",
    "    (\"\", False),                 # Empty\n",
    "], ids=[\n",
    "    \"valid-basic\",\n",
    "    \"valid-uppercase\",\n",
    "    \"valid-special-chars\",\n",
    "    \"invalid-too-short\",\n",
    "    \"invalid-no-uppercase\",\n",
    "    \"invalid-no-number\",\n",
    "    \"invalid-empty\"\n",
    "])\n",
    "def test_password_validation(password, expected):\n",
    "    \"\"\"Test password validation rules.\"\"\"\n",
    "    assert is_valid_password(password) == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1c6d98",
   "metadata": {},
   "source": [
    "### Example 6: Email Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4890800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_email(email):\n",
    "    \"\"\"Basic email validation.\"\"\"\n",
    "    if not email or \"@\" not in email:\n",
    "        return False\n",
    "    if email.count(\"@\") != 1:\n",
    "        return False\n",
    "    if not email.split(\"@\")[1]:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "@pytest.mark.parametrize(\"email, expected\", [\n",
    "    (\"user@example.com\", True),\n",
    "    (\"alice.bob@company.co.uk\", True),\n",
    "    (\"test123@test.org\", True),\n",
    "    (\"invalid\", False),\n",
    "    (\"missing@\", False),\n",
    "    (\"@nodomain.com\", False),\n",
    "    (\"double@@at.com\", False),\n",
    "    (\"\", False),\n",
    "], ids=[\n",
    "    \"valid-simple\",\n",
    "    \"valid-subdomain\",\n",
    "    \"valid-numbers\",\n",
    "    \"invalid-no-at\",\n",
    "    \"invalid-no-domain\",\n",
    "    \"invalid-no-user\",\n",
    "    \"invalid-double-at\",\n",
    "    \"invalid-empty\"\n",
    "])\n",
    "def test_email_validation(email, expected):\n",
    "    \"\"\"Test email validation.\"\"\"\n",
    "    assert is_valid_email(email) == expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a049afd1",
   "metadata": {},
   "source": [
    "### Example 7: Math Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942a1b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide(a, b):\n",
    "    \"\"\"Divide a by b.\"\"\"\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Cannot divide by zero\")\n",
    "    return a / b\n",
    "\n",
    "@pytest.mark.parametrize(\"a, b, expected\", [\n",
    "    (10, 2, 5.0),\n",
    "    (9, 3, 3.0),\n",
    "    (15, 4, 3.75),\n",
    "    (0, 5, 0.0),\n",
    "    (-10, 2, -5.0),\n",
    "])\n",
    "def test_divide_success(a, b, expected):\n",
    "    \"\"\"Test successful division.\"\"\"\n",
    "    result = divide(a, b)\n",
    "    assert result == expected\n",
    "\n",
    "@pytest.mark.parametrize(\"a, b\", [\n",
    "    (10, 0),\n",
    "    (0, 0),\n",
    "    (100, 0),\n",
    "])\n",
    "def test_divide_by_zero(a, b):\n",
    "    \"\"\"Test division by zero raises error.\"\"\"\n",
    "    with pytest.raises(ValueError, match=\"Cannot divide by zero\"):\n",
    "        divide(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09db3ee9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Multiple Parametrize Decorators\n",
    "\n",
    "You can stack `@pytest.mark.parametrize` decorators to test all combinations!\n",
    "\n",
    "### Example 8: Testing Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b504bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply(a, b):\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@pytest.mark.parametrize(\"a\", [1, 2, 3])\n",
    "@pytest.mark.parametrize(\"b\", [10, 20])\n",
    "def test_multiply_combinations(a, b):\n",
    "    \"\"\"Test multiplication with all combinations.\"\"\"\n",
    "    result = multiply(a, b)\n",
    "    assert result == a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfbb89e",
   "metadata": {},
   "source": [
    "**What happens:**\n",
    "- `a` can be 1, 2, or 3\n",
    "- `b` can be 10 or 20\n",
    "- Test runs for all combinations: (1,10), (1,20), (2,10), (2,20), (3,10), (3,20)\n",
    "- Total: 3 √ó 2 = **6 tests**\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "test_example.py::test_multiply_combinations[10-1] PASSED\n",
    "test_example.py::test_multiply_combinations[10-2] PASSED\n",
    "test_example.py::test_multiply_combinations[10-3] PASSED\n",
    "test_example.py::test_multiply_combinations[20-1] PASSED\n",
    "test_example.py::test_multiply_combinations[20-2] PASSED\n",
    "test_example.py::test_multiply_combinations[20-3] PASSED\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fadf591",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Parametrization with Fixtures\n",
    "\n",
    "You can combine parametrized tests with fixtures!\n",
    "\n",
    "### Example 9: User Roles with Fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a108de0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "    def __init__(self, name, role):\n",
    "        self.name = name\n",
    "        self.role = role\n",
    "    \n",
    "    def can_edit(self):\n",
    "        return self.role in [\"admin\", \"editor\"]\n",
    "    \n",
    "    def can_delete(self):\n",
    "        return self.role == \"admin\"\n",
    "\n",
    "@pytest.fixture\n",
    "def create_user():\n",
    "    \"\"\"Factory fixture to create users.\"\"\"\n",
    "    def _create(name, role):\n",
    "        return User(name, role)\n",
    "    return _create\n",
    "\n",
    "@pytest.mark.parametrize(\"role, can_edit, can_delete\", [\n",
    "    (\"admin\", True, True),\n",
    "    (\"editor\", True, False),\n",
    "    (\"viewer\", False, False),\n",
    "])\n",
    "def test_user_permissions(create_user, role, can_edit, can_delete):\n",
    "    \"\"\"Test user permissions based on role.\"\"\"\n",
    "    user = create_user(\"TestUser\", role)\n",
    "    \n",
    "    assert user.can_edit() == can_edit\n",
    "    assert user.can_delete() == can_delete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866dd5a6",
   "metadata": {},
   "source": [
    "## Testing Exceptions\n",
    "\n",
    "Often you need to test that your code **raises** exceptions for invalid inputs.\n",
    "\n",
    "### The Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1820169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide(a, b):\n",
    "    \"\"\"Divide a by b.\"\"\"\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Cannot divide by zero\")\n",
    "    if not isinstance(a, (int, float)) or not isinstance(b, (int, float)):\n",
    "        raise TypeError(\"Both arguments must be numbers\")\n",
    "    return a / b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1acfc75",
   "metadata": {},
   "source": [
    "How do we test that these exceptions are raised correctly?\n",
    "\n",
    "### Using `pytest.raises()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ecae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest\n",
    "\n",
    "def test_divide_by_zero():\n",
    "    \"\"\"Test that dividing by zero raises ValueError.\"\"\"\n",
    "    with pytest.raises(ValueError):\n",
    "        divide(10, 0)\n",
    "\n",
    "def test_divide_invalid_type():\n",
    "    \"\"\"Test that invalid types raise TypeError.\"\"\"\n",
    "    with pytest.raises(TypeError):\n",
    "        divide(\"10\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dafddf4",
   "metadata": {},
   "source": [
    "**How it works:**\n",
    "- Code inside the `with` block is expected to raise an exception\n",
    "- ‚úÖ If the exception is raised ‚Üí test passes\n",
    "- ‚ùå If no exception is raised ‚Üí test fails\n",
    "- ‚ùå If a different exception is raised ‚Üí test fails\n",
    "\n",
    "### Checking Exception Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26ccb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_divide_by_zero_with_message():\n",
    "    \"\"\"Test exception is raised with correct message.\"\"\"\n",
    "    with pytest.raises(ValueError, match=\"Cannot divide by zero\"):\n",
    "        divide(10, 0)\n",
    "\n",
    "def test_divide_invalid_type_with_message():\n",
    "    \"\"\"Test TypeError message.\"\"\"\n",
    "    with pytest.raises(TypeError, match=\"Both arguments must be numbers\"):\n",
    "        divide(\"text\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3d88b1",
   "metadata": {},
   "source": [
    "The `match` parameter accepts a regex pattern. Test passes only if:\n",
    "1. Correct exception type is raised\n",
    "2. Exception message matches the pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bdb274",
   "metadata": {},
   "source": [
    "### Getting Exception Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497b960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_divide_exception_info():\n",
    "    \"\"\"Test and inspect the exception.\"\"\"\n",
    "    with pytest.raises(ValueError) as exc_info:\n",
    "        divide(10, 0)\n",
    "    \n",
    "    # Now you can inspect the exception\n",
    "    assert \"Cannot divide by zero\" in str(exc_info.value)\n",
    "    assert exc_info.type == ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7073aee4",
   "metadata": {},
   "source": [
    "### Practical Example: User Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23c027",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValidationError(Exception):\n",
    "    \"\"\"Custom validation error.\"\"\"\n",
    "    pass\n",
    "\n",
    "class User:\n",
    "    def __init__(self, username, email, age):\n",
    "        if not username:\n",
    "            raise ValidationError(\"Username cannot be empty\")\n",
    "        if \"@\" not in email:\n",
    "            raise ValidationError(\"Invalid email format\")\n",
    "        if age < 0:\n",
    "            raise ValidationError(\"Age cannot be negative\")\n",
    "        if age > 150:\n",
    "            raise ValidationError(\"Age is unrealistic\")\n",
    "        \n",
    "        self.username = username\n",
    "        self.email = email\n",
    "        self.age = age\n",
    "\n",
    "def test_user_empty_username():\n",
    "    \"\"\"Test empty username raises error.\"\"\"\n",
    "    with pytest.raises(ValidationError, match=\"Username cannot be empty\"):\n",
    "        User(\"\", \"alice@example.com\", 25)\n",
    "\n",
    "def test_user_invalid_email():\n",
    "    \"\"\"Test invalid email raises error.\"\"\"\n",
    "    with pytest.raises(ValidationError, match=\"Invalid email format\"):\n",
    "        User(\"alice\", \"invalid-email\", 25)\n",
    "\n",
    "def test_user_negative_age():\n",
    "    \"\"\"Test negative age raises error.\"\"\"\n",
    "    with pytest.raises(ValidationError, match=\"Age cannot be negative\"):\n",
    "        User(\"alice\", \"alice@example.com\", -5)\n",
    "\n",
    "def test_user_unrealistic_age():\n",
    "    \"\"\"Test unrealistic age raises error.\"\"\"\n",
    "    with pytest.raises(ValidationError, match=\"Age is unrealistic\"):\n",
    "        User(\"alice\", \"alice@example.com\", 200)\n",
    "\n",
    "def test_user_valid():\n",
    "    \"\"\"Test valid user creation doesn't raise error.\"\"\"\n",
    "    user = User(\"alice\", \"alice@example.com\", 25)\n",
    "    assert user.username == \"alice\"\n",
    "    assert user.email == \"alice@example.com\"\n",
    "    assert user.age == 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2182e348",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test Markers\n",
    "\n",
    "**Markers** are tags you can apply to tests to categorize them or control their behavior.\n",
    "\n",
    "### Built-in Markers\n",
    "\n",
    "#### `@pytest.mark.skip` - Skip a Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f403941",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.skip(reason=\"Feature not implemented yet\")\n",
    "def test_future_feature():\n",
    "    \"\"\"This test will be skipped.\"\"\"\n",
    "    # Will implement this later\n",
    "    pass\n",
    "\n",
    "@pytest.mark.skip(reason=\"Waiting for API endpoint\")\n",
    "def test_api_integration():\n",
    "    \"\"\"Skip until API is ready.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be60315",
   "metadata": {},
   "source": [
    "**Output:**\n",
    "```\n",
    "test_example.py::test_future_feature SKIPPED (Feature not implemented yet)\n",
    "test_example.py::test_api_integration SKIPPED (Waiting for API endpoint)\n",
    "```\n",
    "\n",
    "Tests are skipped and the reason is shown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d1cc34",
   "metadata": {},
   "source": [
    "#### `@pytest.mark.skipif` - Conditional Skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485ff493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "@pytest.mark.skipif(sys.platform == \"win32\", reason=\"Not supported on Windows\")\n",
    "def test_unix_specific():\n",
    "    \"\"\"This test only runs on Unix systems.\"\"\"\n",
    "    # Unix-specific code\n",
    "    pass\n",
    "\n",
    "@pytest.mark.skipif(sys.version_info < (3, 8), reason=\"Requires Python 3.8+\")\n",
    "def test_modern_python_feature():\n",
    "    \"\"\"This test requires Python 3.8 or higher.\"\"\"\n",
    "    # Use walrus operator := (Python 3.8+)\n",
    "    if (n := 10) > 5:\n",
    "        assert n == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061dbe34",
   "metadata": {},
   "source": [
    "**Common use cases:**\n",
    "- Platform-specific tests (Windows vs Linux vs Mac)\n",
    "- Python version requirements\n",
    "- Optional dependencies\n",
    "- Environment-specific tests (development vs production)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e7e6c4",
   "metadata": {},
   "source": [
    "#### `@pytest.mark.xfail` - Expected to Fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19e07d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.xfail(reason=\"Known bug #123\")\n",
    "def test_known_bug():\n",
    "    \"\"\"This test is expected to fail until bug #123 is fixed.\"\"\"\n",
    "    result = buggy_function()\n",
    "    assert result == expected_value\n",
    "\n",
    "@pytest.mark.xfail(sys.platform == \"win32\", reason=\"Windows bug\")\n",
    "def test_with_windows_bug():\n",
    "    \"\"\"Expected to fail on Windows.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a8ac40",
   "metadata": {},
   "source": [
    "**Output possibilities:**\n",
    "- `XFAIL` - Test failed as expected (good!)\n",
    "- `XPASS` - Test passed unexpectedly (bug might be fixed!)\n",
    "\n",
    "**Use xfail when:**\n",
    "- You know a test will fail but want to track it\n",
    "- There's a known bug that will be fixed later\n",
    "- You're documenting expected failures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380cf623",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Custom Markers\n",
    "\n",
    "You can create your own markers to organize tests!\n",
    "\n",
    "### Defining Custom Markers\n",
    "\n",
    "**In pytest.ini or pyproject.toml:**\n",
    "```ini\n",
    "[pytest]\n",
    "markers =\n",
    "    slow: marks tests as slow (deselect with '-m \"not slow\"')\n",
    "    integration: marks tests as integration tests\n",
    "    unit: marks tests as unit tests\n",
    "    api: marks tests that require API access\n",
    "    smoke: marks tests for smoke testing\n",
    "```\n",
    "\n",
    "### Using Custom Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d65005",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.unit\n",
    "def test_add():\n",
    "    \"\"\"Unit test for addition.\"\"\"\n",
    "    assert add(2, 3) == 5\n",
    "\n",
    "@pytest.mark.unit\n",
    "def test_subtract():\n",
    "    \"\"\"Unit test for subtraction.\"\"\"\n",
    "    assert subtract(10, 5) == 5\n",
    "\n",
    "@pytest.mark.integration\n",
    "def test_database_connection():\n",
    "    \"\"\"Integration test for database.\"\"\"\n",
    "    db = connect_to_database()\n",
    "    assert db.is_connected()\n",
    "\n",
    "@pytest.mark.integration\n",
    "@pytest.mark.slow\n",
    "def test_full_workflow():\n",
    "    \"\"\"Slow integration test.\"\"\"\n",
    "    # Test takes 30 seconds\n",
    "    pass\n",
    "\n",
    "@pytest.mark.api\n",
    "def test_external_api():\n",
    "    \"\"\"Test that calls external API.\"\"\"\n",
    "    response = call_api()\n",
    "    assert response.status == 200\n",
    "\n",
    "@pytest.mark.smoke\n",
    "def test_app_starts():\n",
    "    \"\"\"Smoke test - app starts without crashing.\"\"\"\n",
    "    app = create_app()\n",
    "    assert app is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84010787",
   "metadata": {},
   "source": [
    "### Running Tests by Marker\n",
    "\n",
    "**Run only unit tests:**\n",
    "```bash\n",
    "pytest -m unit\n",
    "```\n",
    "\n",
    "**Run only integration tests:**\n",
    "```bash\n",
    "pytest -m integration\n",
    "```\n",
    "\n",
    "**Run all tests except slow ones:**\n",
    "```bash\n",
    "pytest -m \"not slow\"\n",
    "```\n",
    "\n",
    "**Run unit OR integration tests:**\n",
    "```bash\n",
    "pytest -m \"unit or integration\"\n",
    "```\n",
    "\n",
    "**Run integration tests that are NOT slow:**\n",
    "```bash\n",
    "pytest -m \"integration and not slow\"\n",
    "```\n",
    "\n",
    "**Run smoke tests:**\n",
    "```bash\n",
    "pytest -m smoke\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efe143e",
   "metadata": {},
   "source": [
    "### Practical Example: Test Organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff5ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_calculator.py\n",
    "import pytest\n",
    "\n",
    "# Quick unit tests\n",
    "@pytest.mark.unit\n",
    "@pytest.mark.fast\n",
    "def test_add_basic():\n",
    "    assert add(1, 1) == 2\n",
    "\n",
    "@pytest.mark.unit\n",
    "@pytest.mark.fast\n",
    "def test_subtract_basic():\n",
    "    assert subtract(5, 3) == 2\n",
    "\n",
    "# Slower integration tests\n",
    "@pytest.mark.integration\n",
    "@pytest.mark.slow\n",
    "def test_complex_calculation_with_database():\n",
    "    \"\"\"Test that requires database and takes time.\"\"\"\n",
    "    db = setup_database()  # Slow\n",
    "    result = perform_complex_calc(db)  # Slow\n",
    "    assert result is not None\n",
    "\n",
    "# API tests (require network)\n",
    "@pytest.mark.api\n",
    "@pytest.mark.integration\n",
    "def test_fetch_data_from_api():\n",
    "    \"\"\"Test that calls external API.\"\"\"\n",
    "    data = fetch_from_api()\n",
    "    assert data is not None\n",
    "\n",
    "# Smoke tests (must always pass)\n",
    "@pytest.mark.smoke\n",
    "def test_import_works():\n",
    "    \"\"\"Verify basic imports work.\"\"\"\n",
    "    from calculator import add, subtract\n",
    "    assert callable(add)\n",
    "    assert callable(subtract)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97324abd",
   "metadata": {},
   "source": [
    "**Development workflow:**\n",
    "```bash\n",
    "# Quick feedback during development\n",
    "pytest -m \"unit and fast\"  # Run only fast unit tests\n",
    "\n",
    "# Before committing\n",
    "pytest -m \"unit or smoke\"  # Unit tests + smoke tests\n",
    "\n",
    "# Full test suite\n",
    "pytest  # Run everything\n",
    "\n",
    "# CI/CD pipeline\n",
    "pytest -m \"not slow\"  # Skip slow tests for faster feedback\n",
    "pytest -m integration  # Run integration tests separately\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91907e1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## conftest.py - Shared Configuration\n",
    "\n",
    "`conftest.py` is a special file where you can define fixtures and configuration that's shared across multiple test files.\n",
    "\n",
    "### File Structure\n",
    "```\n",
    "project/\n",
    "‚îú‚îÄ‚îÄ src/\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ calculator.py\n",
    "‚îú‚îÄ‚îÄ tests/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ conftest.py          ‚Üê Shared fixtures here\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ test_calculator.py\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ test_database.py\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ test_api.py\n",
    "```\n",
    "\n",
    "### Example conftest.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25888a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests/conftest.py\n",
    "import pytest\n",
    "\n",
    "@pytest.fixture\n",
    "def sample_user():\n",
    "    \"\"\"Fixture available to all test files.\"\"\"\n",
    "    return {\n",
    "        \"username\": \"testuser\",\n",
    "        \"email\": \"test@example.com\",\n",
    "        \"age\": 25\n",
    "    }\n",
    "\n",
    "@pytest.fixture\n",
    "def sample_users():\n",
    "    \"\"\"List of users for testing.\"\"\"\n",
    "    return [\n",
    "        {\"username\": \"alice\", \"email\": \"alice@example.com\", \"age\": 25},\n",
    "        {\"username\": \"bob\", \"email\": \"bob@example.com\", \"age\": 30},\n",
    "        {\"username\": \"charlie\", \"email\": \"charlie@example.com\", \"age\": 35}\n",
    "    ]\n",
    "\n",
    "@pytest.fixture(scope=\"session\")\n",
    "def database_connection():\n",
    "    \"\"\"Create database connection once per test session.\"\"\"\n",
    "    print(\"\\nüîå Connecting to test database...\")\n",
    "    connection = connect_to_test_db()\n",
    "    \n",
    "    yield connection\n",
    "    \n",
    "    print(\"\\nüîå Closing database connection...\")\n",
    "    connection.close()\n",
    "\n",
    "@pytest.fixture\n",
    "def clean_database(database_connection):\n",
    "    \"\"\"Provide clean database for each test.\"\"\"\n",
    "    yield database_connection\n",
    "    # Clean up after test\n",
    "    database_connection.truncate_all_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a70369e",
   "metadata": {},
   "source": [
    "### Using Fixtures from conftest.py\n",
    "\n",
    "**In test_calculator.py:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532c1563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests/test_calculator.py\n",
    "# No need to import fixtures from conftest.py - they're automatically available!\n",
    "\n",
    "def test_user_age(sample_user):\n",
    "    \"\"\"Use sample_user fixture from conftest.py.\"\"\"\n",
    "    assert sample_user[\"age\"] == 25\n",
    "\n",
    "def test_count_users(sample_users):\n",
    "    \"\"\"Use sample_users fixture from conftest.py.\"\"\"\n",
    "    assert len(sample_users) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e0c3dd",
   "metadata": {},
   "source": [
    "**In test_database.py:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06b300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests/test_database.py\n",
    "# Same fixtures are available here too!\n",
    "\n",
    "def test_database_query(clean_database):\n",
    "    \"\"\"Use clean_database fixture.\"\"\"\n",
    "    clean_database.insert(\"users\", sample_user)\n",
    "    result = clean_database.query(\"SELECT * FROM users\")\n",
    "    assert len(result) == 1\n",
    "\n",
    "def test_user_creation(sample_user, clean_database):\n",
    "    \"\"\"Use multiple fixtures from conftest.py.\"\"\"\n",
    "    clean_database.insert(\"users\", sample_user)\n",
    "    user = clean_database.get_user(sample_user[\"username\"])\n",
    "    assert user is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d06d82d",
   "metadata": {},
   "source": [
    "### Nested conftest.py Files\n",
    "\n",
    "You can have multiple `conftest.py` files at different levels:\n",
    "\n",
    "```\n",
    "project/\n",
    "‚îú‚îÄ‚îÄ tests/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ conftest.py           ‚Üê Available to all tests\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ unit/\n",
    "‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ conftest.py       ‚Üê Available only to unit tests\n",
    "‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_math.py\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ integration/\n",
    "‚îÇ       ‚îú‚îÄ‚îÄ conftest.py       ‚Üê Available only to integration tests\n",
    "‚îÇ       ‚îî‚îÄ‚îÄ test_api.py\n",
    "```\n",
    "\n",
    "Fixtures in nested `conftest.py` override parent fixtures with the same name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa67e49f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Practical Example: Complete Test Suite\n",
    "\n",
    "### Project Structure\n",
    "```\n",
    "my_app/\n",
    "‚îú‚îÄ‚îÄ src/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ user.py\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ database.py\n",
    "‚îú‚îÄ‚îÄ tests/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ conftest.py\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ test_user.py\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ test_database.py\n",
    "‚îî‚îÄ‚îÄ pytest.ini\n",
    "```\n",
    "\n",
    "### pytest.ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a1e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# pytest.ini\n",
    "[pytest]\n",
    "markers =\n",
    "    unit: Unit tests (fast, no external dependencies)\n",
    "    integration: Integration tests (may be slower)\n",
    "    slow: Slow tests (> 1 second)\n",
    "    database: Tests that require database\n",
    "    api: Tests that require API access\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea574380",
   "metadata": {},
   "source": [
    "### conftest.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests/conftest.py\n",
    "import pytest\n",
    "from src.database import Database\n",
    "from src.user import User\n",
    "\n",
    "@pytest.fixture(scope=\"session\")\n",
    "def db_connection():\n",
    "    \"\"\"Database connection shared across all tests.\"\"\"\n",
    "    print(\"\\nüóÑÔ∏è  Connecting to database...\")\n",
    "    db = Database(\"test.db\")\n",
    "    yield db\n",
    "    print(\"\\nüóÑÔ∏è  Closing database...\")\n",
    "    db.close()\n",
    "\n",
    "@pytest.fixture\n",
    "def clean_db(db_connection):\n",
    "    \"\"\"Clean database for each test.\"\"\"\n",
    "    db_connection.clear()\n",
    "    yield db_connection\n",
    "\n",
    "@pytest.fixture\n",
    "def sample_user_data():\n",
    "    \"\"\"Sample user data.\"\"\"\n",
    "    return {\n",
    "        \"username\": \"alice\",\n",
    "        \"email\": \"alice@example.com\",\n",
    "        \"age\": 25\n",
    "    }\n",
    "\n",
    "@pytest.fixture\n",
    "def created_user(clean_db, sample_user_data):\n",
    "    \"\"\"Create a user in the database.\"\"\"\n",
    "    user = User(**sample_user_data)\n",
    "    clean_db.add_user(user)\n",
    "    return user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b8516",
   "metadata": {},
   "source": [
    "### test_user.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c9086a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests/test_user.py\n",
    "import pytest\n",
    "from src.user import User, ValidationError\n",
    "\n",
    "# Unit tests - fast, no database\n",
    "@pytest.mark.unit\n",
    "class TestUserValidation:\n",
    "    \"\"\"Unit tests for user validation.\"\"\"\n",
    "    \n",
    "    def test_valid_user(self, sample_user_data):\n",
    "        \"\"\"Test creating valid user.\"\"\"\n",
    "        user = User(**sample_user_data)\n",
    "        assert user.username == \"alice\"\n",
    "    \n",
    "    def test_empty_username(self):\n",
    "        \"\"\"Test empty username raises error.\"\"\"\n",
    "        with pytest.raises(ValidationError, match=\"Username cannot be empty\"):\n",
    "            User(\"\", \"email@example.com\", 25)\n",
    "    \n",
    "    @pytest.mark.parametrize(\"email\", [\n",
    "        \"invalid\",\n",
    "        \"missing@\",\n",
    "        \"@nodomain\",\n",
    "        \"\",\n",
    "    ])\n",
    "    def test_invalid_email(self, email):\n",
    "        \"\"\"Test invalid emails raise error.\"\"\"\n",
    "        with pytest.raises(ValidationError, match=\"Invalid email\"):\n",
    "            User(\"alice\", email, 25)\n",
    "\n",
    "# Integration tests - require database\n",
    "@pytest.mark.integration\n",
    "@pytest.mark.database\n",
    "class TestUserDatabase:\n",
    "    \"\"\"Integration tests with database.\"\"\"\n",
    "    \n",
    "    def test_save_user(self, clean_db, sample_user_data):\n",
    "        \"\"\"Test saving user to database.\"\"\"\n",
    "        user = User(**sample_user_data)\n",
    "        clean_db.add_user(user)\n",
    "        \n",
    "        retrieved = clean_db.get_user(\"alice\")\n",
    "        assert retrieved.username == \"alice\"\n",
    "    \n",
    "    def test_delete_user(self, clean_db, created_user):\n",
    "        \"\"\"Test deleting user from database.\"\"\"\n",
    "        clean_db.delete_user(created_user.username)\n",
    "        \n",
    "        retrieved = clean_db.get_user(created_user.username)\n",
    "        assert retrieved is None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596e28e7",
   "metadata": {},
   "source": [
    "### Running the Test Suite\n",
    "\n",
    "**Run all tests:**\n",
    "```bash\n",
    "pytest\n",
    "```\n",
    "\n",
    "**Run only unit tests (fast):**\n",
    "```bash\n",
    "pytest -m unit\n",
    "```\n",
    "\n",
    "**Run only integration tests:**\n",
    "```bash\n",
    "pytest -m integration\n",
    "```\n",
    "\n",
    "**Run with verbose output:**\n",
    "```bash\n",
    "pytest -v\n",
    "```\n",
    "\n",
    "**Run specific test file:**\n",
    "```bash\n",
    "pytest tests/test_user.py\n",
    "```\n",
    "\n",
    "**Run specific test class:**\n",
    "```bash\n",
    "pytest tests/test_user.py::TestUserValidation\n",
    "```\n",
    "\n",
    "**Run specific test:**\n",
    "```bash\n",
    "pytest tests/test_user.py::TestUserValidation::test_valid_user\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fee6e4e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "### 1. Organize Tests with Markers\n",
    "\n",
    "**‚úÖ Good - Well organized:**\n",
    "```python\n",
    "@pytest.mark.unit\n",
    "@pytest.mark.fast\n",
    "def test_addition():\n",
    "    ...\n",
    "\n",
    "@pytest.mark.integration\n",
    "@pytest.mark.slow\n",
    "@pytest.mark.database\n",
    "def test_full_workflow():\n",
    "    ...\n",
    "```\n",
    "\n",
    "### 2. Use conftest.py for Shared Fixtures\n",
    "\n",
    "**‚ùå Bad - Duplicating fixtures:**\n",
    "```python\n",
    "# test_file1.py\n",
    "@pytest.fixture\n",
    "def sample_user():\n",
    "    return {\"name\": \"Alice\"}\n",
    "\n",
    "# test_file2.py\n",
    "@pytest.fixture\n",
    "def sample_user():  # Duplicated!\n",
    "    return {\"name\": \"Alice\"}\n",
    "```\n",
    "\n",
    "**‚úÖ Good - Shared in conftest.py:**\n",
    "```python\n",
    "# conftest.py\n",
    "@pytest.fixture\n",
    "def sample_user():\n",
    "    return {\"name\": \"Alice\"}\n",
    "\n",
    "# Both test files can use it!\n",
    "```\n",
    "\n",
    "### 3. Test Exceptions Explicitly\n",
    "\n",
    "**‚úÖ Good:**\n",
    "```python\n",
    "def test_division_by_zero():\n",
    "    with pytest.raises(ValueError, match=\"Cannot divide by zero\"):\n",
    "        divide(10, 0)\n",
    "```\n",
    "\n",
    "### 4. Use Descriptive Marker Names\n",
    "\n",
    "**‚ùå Bad:**\n",
    "```python\n",
    "@pytest.mark.test1\n",
    "@pytest.mark.slow\n",
    "```\n",
    "\n",
    "**‚úÖ Good:**\n",
    "```python\n",
    "@pytest.mark.integration\n",
    "@pytest.mark.database\n",
    "@pytest.mark.slow\n",
    "```\n",
    "\n",
    "### 5. Skip vs XFail\n",
    "\n",
    "**Use `skip` when:**\n",
    "- Test isn't relevant (platform-specific)\n",
    "- Feature not implemented yet\n",
    "- Missing dependencies\n",
    "\n",
    "**Use `xfail` when:**\n",
    "- Known bug that will be fixed\n",
    "- Test documents expected failure\n",
    "- Want to track failures\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b242379",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "‚úÖ **pytest.raises()** - Test that exceptions are raised correctly  \n",
    "‚úÖ **Markers** - Tag and organize tests  \n",
    "‚úÖ **@pytest.mark.skip** - Skip tests  \n",
    "‚úÖ **@pytest.mark.skipif** - Conditional skip  \n",
    "‚úÖ **@pytest.mark.xfail** - Expected failures  \n",
    "‚úÖ **Custom markers** - Create your own test categories  \n",
    "‚úÖ **conftest.py** - Share fixtures across test files  \n",
    "‚úÖ **Running specific tests** - Use `-m` flag with markers  \n",
    "\n",
    "### Key Commands:\n",
    "\n",
    "```bash\n",
    "pytest -m unit                    # Run unit tests\n",
    "pytest -m \"not slow\"             # Skip slow tests\n",
    "pytest -m \"integration and database\"  # Multiple markers\n",
    "pytest -v                        # Verbose output\n",
    "pytest -k \"pattern\"              # Run tests matching pattern\n",
    "```\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "You now have all the essential pytest knowledge! Practice by:\n",
    "- Writing tests for your own projects\n",
    "- Organizing tests with markers\n",
    "- Creating shared fixtures in conftest.py\n",
    "- Testing edge cases and exceptions\n",
    "\n",
    "Happy testing! üéâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "    def __init__(self, name, role):\n",
    "        self.name = name\n",
    "        self.role = role\n",
    "    \n",
    "    def can_edit(self):\n",
    "        return self.role in [\"admin\", \"editor\"]\n",
    "    \n",
    "    def can_delete(self):\n",
    "        return self.role == \"admin\"\n",
    "\n",
    "@pytest.fixture\n",
    "def create_user():\n",
    "    \"\"\"Factory fixture to create users.\"\"\"\n",
    "    def _create(name, role):\n",
    "        return User(name, role)\n",
    "    return _create\n",
    "\n",
    "@pytest.mark.parametrize(\"role, can_edit, can_delete\", [\n",
    "    (\"admin\", True, True),\n",
    "    (\"editor\", True, False),\n",
    "    (\"viewer\", False, False),\n",
    "])\n",
    "def test_user_permissions(create_user, role, can_edit, can_delete):\n",
    "    \"\"\"Test user permissions based on role.\"\"\"\n",
    "    user = create_user(\"TestUser\", role)\n",
    "    \n",
    "    assert user.can_edit() == can_edit\n",
    "    assert user.can_delete() == can_delete"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
